# -*- coding: utf-8 -*-
"""4. Model Deployment on Streamlit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r6_pQpMG3Yiwcdbu3qZ3Kz9wlPP9wxGk
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

pip install streamlit

import streamlit as st
import numpy as np
import pandas as pd
import tensorflow as tf
from PIL import Image

from tensorflow.keras.models import load_model

# Load pre-trained model(VGG16 with fine-tuning)
model_vgg16 = load_model('/content/drive/MyDrive/Colab Notebooks/model/Bone_Fracture_Binary_Classifier.h5')

# Define a function to preprocess the uploaded image
def preprocess_image(image):
    image = image.resize((224, 224))  # Resize to match model input size
    image = np.array(image) / 255.0   # Normalize to [0, 1]
    image = np.expand_dims(image, axis=0)  # Add batch dimension
    return image

# Define a function to make predictions
def predict(image):
    processed_image = preprocess_image(image)
    predictions = model.predict(processed_image)
    return predictions

# Streamlit app
st.title("Binary X-ray image classification for bone fracture")

# File uploader
uploaded_file = st.file_uploader("Upload an X-ray image", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # Display uploaded image
    image = Image.open(uploaded_file)
    st.image(image, caption='Uploaded Image.', use_column_width=True)

    st.write("")
    st.write("Classifying...")

    # Make prediction
    predictions = predict(image)

    # Display prediction
    class_names = ['Fractured', 'Not Fractured']  # Replace with your class names
    predicted_class = class_names[np.argmax(predictions)]
    st.write(f"Prediction: {predicted_class}")

!streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]